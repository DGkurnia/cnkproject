{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/cnkproject/blob/main/BMLP_Derfansyah_Guswiranata_Kurnia_klasifikasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan untuk pengelolaan data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Grafik\n",
        "import matplotlib.pyplot as plt #grafik dasar\n",
        "import seaborn as sns\n",
        "import datetime"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pelabelan untuk 'onehotencoder'\n",
        "from sklearn.preprocessing import LabelBinarizer as lbin"
      ],
      "metadata": {
        "id": "trwImvqYHw5-"
      },
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian svm(p1)\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler"
      ],
      "metadata": {
        "id": "nJm5Mw1H3V6h"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian klasifikasi 'randomforest'\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "syO5ZWQT00Op"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pengunduhan dataset ke google colab\n",
        "from google.colab import files\n",
        "#ke proses 'upload'"
      ],
      "metadata": {
        "id": "c7FAzF641Y18"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#proses 'upload'\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F_1zCMBK1aBp",
        "outputId": "dd085e66-07c9-4d5a-dda8-e3f020daa250"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b2d3eb97-3e94-4139-8f37-4ffbb7c86ed4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b2d3eb97-3e94-4139-8f37-4ffbb7c86ed4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hslclstr.csv to hslclstr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pengelolaan file\n",
        "import os #untuk os\n",
        "import time #waktu\n",
        "import datetime #tanggal\n",
        "import gc #pengunduhan file per batch"
      ],
      "metadata": {
        "id": "ndXvjNhh3ZaY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Penyimpanan hasil sementara di google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3iqu6N43l32",
        "outputId": "b256d5f9-f861-4171-ee4e-2fffe78e99b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inisiasi berat sampel\n",
        "from sklearn.utils.class_weight import compute_sample_weight as csw #inspeksi berat dl"
      ],
      "metadata": {
        "id": "3ePCGLMy0bhI"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian multiprocessing melalui instalasi pool\n",
        "import warnings #peringatan\n",
        "import multiprocessing as mp #untuk multiprocessing\n",
        "from multiprocessing import Pool"
      ],
      "metadata": {
        "id": "OxflnfjP3wry"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyimpanan hasil melalui dill\n",
        "! pip install dill\n",
        "import dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIIj64Qs3fIF",
        "outputId": "8b659b19-7ba5-45f7-dad8-f09700cbb4a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cek data\n",
        "df = pd.read_csv('/content/hslclstr.csv')\n",
        "dfc = df.copy() #jangan pakai data asli"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cek hasil\n",
        "smpl = dfc.head(7)\n",
        "inf = dfc.info() #informasi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3iFgini4lOP",
        "outputId": "05f03a68-45c0-49b9-e250-e5583af11058"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 16 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   img                          64016 non-null  object \n",
            " 1   title                        64016 non-null  object \n",
            " 2   console                      64016 non-null  object \n",
            " 3   genre                        64016 non-null  object \n",
            " 4   publisher                    64016 non-null  object \n",
            " 5   total_sales                  64016 non-null  float64\n",
            " 6   na_sales                     64016 non-null  float64\n",
            " 7   jp_sales                     64016 non-null  float64\n",
            " 8   pal_sales                    64016 non-null  float64\n",
            " 9   other_sales                  64016 non-null  float64\n",
            " 10  critic_score                 64016 non-null  float64\n",
            " 11  release_date                 64016 non-null  object \n",
            " 12  last_update                  64016 non-null  object \n",
            " 13  kemungkinan generasi         64016 non-null  int64  \n",
            " 14  kemungkinan jenis permainan  64016 non-null  int64  \n",
            " 15  Label                        64016 non-null  object \n",
            "dtypes: float64(6), int64(2), object(8)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi label untuk sampel\n",
        "lbl = dfc['Label'].copy()\n",
        "print(lbl.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49_-B54J5LvE",
        "outputId": "44d69bde-4f55-42b0-deaa-bb0976cc7c50"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    game kurang berkenan dengan fokus pencarian ke...\n",
            "1    game kurang berkenan dengan fokus pencarian ke...\n",
            "2    game kurang berkenan dengan fokus pencarian ke...\n",
            "3                game dengan tujuan utama pencari duit\n",
            "4    game kurang berkenan dengan fokus pencarian ke...\n",
            "5                game dengan tujuan utama pencari duit\n",
            "6                game dengan tujuan utama pencari duit\n",
            "Name: Label, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi pembagian data\n",
        "inspk = dfc.iloc[:,5:11].copy() #numerikal untuk klasifikasi kluster\n",
        "inspk.info()"
      ],
      "metadata": {
        "id": "vM4BLUu_40kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b9d0e72-b654-4147-a08e-f0e167842900"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   total_sales   64016 non-null  float64\n",
            " 1   na_sales      64016 non-null  float64\n",
            " 2   jp_sales      64016 non-null  float64\n",
            " 3   pal_sales     64016 non-null  float64\n",
            " 4   other_sales   64016 non-null  float64\n",
            " 5   critic_score  64016 non-null  float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 2.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#numerisasi label (identifikasi jenis label)\n",
        "jnslbl = dfc['Label'].copy()\n",
        "jnslbl.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2klaS2KE7Ct",
        "outputId": "fb939b4b-cbc8-4f6e-d7a6-567360345c75"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Series name: Label\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "64016 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 500.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sumbu x\n",
        "xcls = inspk.copy() #pakai numerik"
      ],
      "metadata": {
        "id": "hdUVAumDGa2c"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumbu x  **(xcls)** adalah nilai numerikal dari tabel yang terdiri dari\n",
        "* Penjualan dari lima indikator (total, spesifika amerika utara, jepang, PAL, lain-lain)\n",
        "* Nilai kritik"
      ],
      "metadata": {
        "id": "lbtI-04vGloX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan pembagian data (untuk kluster)\n",
        "ycls = jnslbl #masih kata-kata\n",
        "#pelabelan dengan 'ohen.onehotencoder' (pembentukan ulang)\n",
        "bntkbaru, label = pd.factorize(ycls)\n",
        "#inspeksi hasil\n",
        "print(bntkbaru)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7217677-ab74-40eb-cf3d-d048fe26858e"
      },
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 0 ... 2 2 2]\n",
            "Index(['game kurang berkenan dengan fokus pencarian keuntungan',\n",
            "       'game dengan tujuan utama pencari duit',\n",
            "       'game favortit dengan keuntungan rendah'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sampel kolom pelabelan"
      ],
      "metadata": {
        "id": "x8dr89b17Ii4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pembentukan ulang\n",
        "enkoding = bntkbaru.reshape(-1,1)\n",
        "#inisiasi ohen\n",
        "encoder = lbin()\n",
        "#penyesuaian data\n",
        "lblohen = encoder.fit_transform(enkoding)"
      ],
      "metadata": {
        "id": "GGwhIGqbIbPC"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#konversi ke df untuk kluster jadi\n",
        "dflbl = pd.DataFrame(lblohen, columns=encoder.classes_)\n",
        "#cek hasil\n",
        "smpllbl = dflbl.head(7)\n",
        "print(smpllbl) #inspeksi hasil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K6VVEnKJD6c",
        "outputId": "6d0fd1b4-e647-4dc0-d1b7-96fa8b159c04"
      },
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0  1  2\n",
            "0  1  0  0\n",
            "1  1  0  0\n",
            "2  1  0  0\n",
            "3  0  1  0\n",
            "4  1  0  0\n",
            "5  0  1  0\n",
            "6  0  1  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai ini **(ycls)** menjadi komponen untuk penyatuan"
      ],
      "metadata": {
        "id": "eVozCln-JVYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#proses scaling untuk sumbu X\n",
        "rbsscal = RobustScaler() #untuk SVM\n",
        "xclscl = rbsscal.fit_transform(xcls) #untuk metode SVM\n",
        "#pengubahan ke data frame untuk evaluasi\n",
        "dfxcl = pd.DataFrame(xclscl, columns=xcls.columns)"
      ],
      "metadata": {
        "id": "hCT3Q_vtT01z"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi kolom\n",
        "print(dfxcl.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRuxkA5lUAvu",
        "outputId": "cc917616-7967-4312-b1e9-9e71fd6f44aa"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   total_sales  na_sales  jp_sales  pal_sales  other_sales  critic_score\n",
            "0       1016.0     637.0      99.0       9.85         3.12      1.105263\n",
            "1        969.5     606.0      60.0       9.71         3.02      1.263158\n",
            "2        807.5     841.0      47.0       5.49         1.78      1.210526\n",
            "3        793.0     906.0       6.0       5.33         1.42      1.210526\n",
            "4        754.5     618.0      41.0       6.05         2.44      0.421053\n",
            "5        741.0     907.0      13.0       4.29         1.33      0.736842\n",
            "6        737.0     976.0      11.0       3.73         1.14      0.789474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7 kolom"
      ],
      "metadata": {
        "id": "OSTrNylU4b6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan df ternormalisasi untuk Random forest classifier\n",
        "mnmxscal = MinMaxScaler() #untuk RFC('RandomforestClasTree')\n",
        "xclsmm = mnmxscal.fit_transform(xcls)"
      ],
      "metadata": {
        "id": "srzQSs7a31PF"
      },
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bentuk nilai data untuk teknik RCT\n",
        "dfxclmm = pd.DataFrame(xclsmm, columns=xcls.columns)\n",
        "#cek hasil\n",
        "print(dfxclmm.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PMb9An14Lp_",
        "outputId": "1f5606ed-d587-4af7-9875-af02b91c5e78"
      },
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   total_sales  na_sales  jp_sales  pal_sales  other_sales  critic_score\n",
            "0     1.000000  0.652664  0.464789   1.000000     1.000000      0.933333\n",
            "1     0.954232  0.620902  0.281690   0.985787     0.967949      0.966667\n",
            "2     0.794783  0.861680  0.220657   0.557360     0.570513      0.955556\n",
            "3     0.780512  0.928279  0.028169   0.541117     0.455128      0.955556\n",
            "4     0.742618  0.633197  0.192488   0.614213     0.782051      0.788889\n",
            "5     0.729331  0.929303  0.061033   0.435533     0.426282      0.855556\n",
            "6     0.725394  1.000000  0.051643   0.378680     0.365385      0.866667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#deklarasi nilai X dan y\n",
        "X_train, X_test, y_train, y_test = train_test_split(xclscl, ycls, test_size=0.25, random_state=42) #untuk cek kondisi 1\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(xclscl, ycls, test_size=0.225, random_state=42) #untuk RCT"
      ],
      "metadata": {
        "id": "vOTh55sKJSZW"
      },
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi 'berat sampel'\n",
        "brtsampel = csw(class_weight='balanced', y=y_test) #dipakai di kedua metode"
      ],
      "metadata": {
        "id": "G4iGKOIz00Xg"
      },
      "execution_count": 201,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rincian Percobaan\n",
        "* Percobaan pertama untuk kedua metode berlangsung dengan rasio (33/7)\n",
        "* Percobaan kedua dengan rasio (3/1)\n",
        "* Percobaan ketiga dengan rasio (31/9)"
      ],
      "metadata": {
        "id": "V3pdLLjkPFeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi penentu akurasi melalui KNN\n",
        "def train_and_evaluate(k, sample_weight=None):\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Pembulatan metrik\n",
        "    accuracy = accuracy_score(y_test, y_pred, sample_weight=sample_weight[:len(y_test)]) # Akurasi yang dinormalkan\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=sample_weight[:len(y_test)]) # Penyesuaian di presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted',sample_weight=sample_weight[:len(y_test)]) #Penyesuaian di kondisi recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted',sample_weight=sample_weight[:len(y_test)]) #Penyesuaian di skor F1\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Total Tetangga k={k}\")\n",
        "    print(f\"Nilai Akurasi: {accuracy:.4f}, Presisi: {precision:.4f}, Aspek Recall: {recall:.4f}, Skor F1: {f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    if (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "       (accuracy >= 0.92 and precision >= 0.92 and recall >= 0.92 and f1 >= 0.92):\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "         (accuracy < 0.92 and precision < 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "        print(\"Hasil masih bisa disimpan.\")\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall < 0.87 and f1 < 0.87) or \\\n",
        "         (accuracy > 0.92 and precision > 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "         print(\"Ada masalah di recall dan nilai f1.\")\n",
        "         return None\n",
        "    else:\n",
        "        print(\"Hasil tidak pantas disimpan.\")\n",
        "        return None\n",
        "  #ke pembentukan matriks"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi evaluasi matriks\n",
        "def generate_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    cm_rounded = np.round(cm.astype(float), decimals=4)  # Pembulatan untuk kemudahan nilai\n",
        "    print(\"Hasil Confusion Matriks:\")\n",
        "    print(cm_rounded)\n",
        "    return cm_rounded\n",
        "#ke eksekusi asli"
      ],
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deklarasi parameter batas di KNN\n",
        "param_grid = range(131, 140)\n",
        "#Paralelisasi melalui KNN\n",
        "if __name__ == '__main__':\n",
        "    with Pool() as pool:\n",
        "        results = pool.starmap(train_and_evaluate, [(k, brtsampel) for k in param_grid])\n",
        "\n",
        "    # Filter out empty results\n",
        "    filtered_results = [result for result in results if result is not None]\n",
        "\n",
        "    # Get the best result\n",
        "    best_result = max(filtered_results, key=lambda x: x[1], default=None)\n",
        "\n",
        "    if best_result:\n",
        "        # Pembulatans\n",
        "        rounded_best_result = (\n",
        "            best_result[0],  # Nilai awal\n",
        "            round(best_result[1], 3),  # Pembulatan 1\n",
        "            round(best_result[2], 3),  # Pembulatan 2\n",
        "            round(best_result[3], 3),  # Pembulatan 3\n",
        "            round(best_result[4], 3),  # Pembulatan 4\n",
        "            best_result[5],  # Predictions (y_pred)\n",
        "            best_result[6]   # Informasi tambahan\n",
        "        )\n",
        "\n",
        "        # Simpan nilai terbaik dari dill\n",
        "        with open('best_knn_result.dill', 'wb') as f:\n",
        "            dill.dump(rounded_best_result, f)\n",
        "\n",
        "        _, _, _, _, _, y_pred, _ = rounded_best_result\n",
        "        cm = generate_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Simpan hasil matriks terbaik saja\n",
        "        with open('best_confusion_matrix.dill', 'wb') as cm_file:\n",
        "            dill.dump(cm, cm_file)\n",
        "\n",
        "        # Print the best rounded result\n",
        "        print(\"Best Result:\", rounded_best_result)\n",
        "#eksekusi KNN"
      ],
      "metadata": {
        "id": "VOTaGStgLZd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 911
        },
        "outputId": "f520696a-c31a-4e3f-dccd-c143d3f2850f"
      },
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tetangga k=133\n",
            "Nilai Akurasi: 0.4273, Presisi: 0.4339, Aspek Recall: 0.4273, Skor F1: 0.4064\n",
            "Total Tetangga k=131\n",
            "Nilai Akurasi: 0.4257, Presisi: 0.4322, Aspek Recall: 0.4257, Skor F1: 0.4036\n",
            "Total Tetangga k=135\n",
            "Nilai Akurasi: 0.4263, Presisi: 0.4326, Aspek Recall: 0.4263, Skor F1: 0.4048\n",
            "Total Tetangga k=137\n",
            "Nilai Akurasi: 0.4243, Presisi: 0.4284, Aspek Recall: 0.4243, Skor F1: 0.4033\n",
            "Total Tetangga k=139\n",
            "Nilai Akurasi: 0.4303, Presisi: 0.4332, Aspek Recall: 0.4303, Skor F1: 0.4132\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Found input variables with inconsistent numbers of samples: [14404, 16004]",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/lib/python3.10/multiprocessing/pool.py\", line 51, in starmapstar\n    return list(itertools.starmap(args[0], args[1]))\n  File \"<ipython-input-202-d0d56bd1369f>\", line 19, in train_and_evaluate\n    report = classification_report(y_test2, y_pred)\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 2626, in classification_report\n    Label of the positive class. `pos_label` will be inferred in the\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\", line 103, in _check_targets\n    if y_type not in [\"binary\", \"multiclass\", \"multilabel-indicator\"]:\n  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\", line 457, in check_consistent_length\n    elif accept_sparse is not True:\nValueError: Found input variables with inconsistent numbers of samples: [14404, 16004]\n\"\"\"",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-24d5655cabd0>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbrtsampel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Filter out empty results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         '''\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14404, 16004]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap pertama RFC (pelacakan nilai ccp alpha)\n",
        "nialpf = np.arange(1.1e-4, 0.11, 1.1e-4) #Nilai alfa\n",
        "itmaks = 300\n",
        "tolerance = 1.5e-3\n",
        "best_alpha = None\n",
        "best_accuracy = -np.inf\n",
        "best_f1 = -np.inf\n",
        "previous_best_accuracy = None\n",
        "#ke iterasi pelacakan nilai ccp alpha"
      ],
      "metadata": {
        "id": "povKRBbsg_hI"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi inspeksi nilai ccp alpha optimal\n",
        "def evaluasi_alfa(alpha):\n",
        "    rfc = RandomForestClassifier(random_state=50, ccp_alpha=alpha)\n",
        "    rfc.fit(X_train, y_train, sample_weight=brtsampel)\n",
        "    y_pred = rfc.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Pembulatan akurasi\n",
        "    accuracy_rounded = round(accuracy, 3)\n",
        "\n",
        "    #penyetelan\n",
        "    brtsmplnorm = brtsampel[:len(y_test)]\n",
        "\n",
        "    # Penghindaran Peringatan di normalisasi\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', sample_weight=brtsmplnorm, zero_division=0)  # Nilai f1\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsmplnorm, zero_division=0)  # indikator presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', sample_weight=brtsmplnorm, zero_division=0)  # Nilai Recall\n",
        "\n",
        "    return alpha, accuracy_rounded, f1, precision, recall  # Return values\n",
        "\n",
        "# Iterasi melalui jangkauan nilai alfa\n",
        "for iteration in range(itmaks):\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(evaluasi_alfa, nialpf)\n",
        "\n",
        "    for alpha, accuracy, f1, precision, recall in results:\n",
        "        if accuracy > best_accuracy or (accuracy == best_accuracy and f1 > best_f1):\n",
        "            best_alpha = alpha\n",
        "            best_accuracy = accuracy\n",
        "            best_f1 = f1\n",
        "\n",
        "        # Pemeriksaan untuk nilai minimal (atau optimal)\n",
        "        if (accuracy >= 0.92 and precision >= 0.92 and\n",
        "            recall >= 0.92 and f1 >= 0.92) or \\\n",
        "           (accuracy >= 0.87 and precision >= 0.87 and\n",
        "            recall >= 0.87 and f1 >= 0.87):\n",
        "            print(f\"Optimal metrics reached with ccp_alpha: {alpha}, \"\n",
        "                  f\"Akurasi: {accuracy:.3f}, F1 Score: {f1:.2f}, \"\n",
        "                  f\"Precision: {precision:.2f}, Recall: {recall:.2f}. Stopping search.\")\n",
        "            break\n",
        "\n",
        "    # Pengaturan Nilai alfa\n",
        "    nialpf = np.linspace(max(0.001, best_alpha - 0.005), min(0.1, best_alpha + 0.005), num=10)\n",
        "\n",
        "    # Check for tolerance to stop early\n",
        "    if iteration > 0 and abs(best_accuracy - previous_best_accuracy) < tolerance:\n",
        "        print(\"Penghentian terjadi karena sudah melewati batas toleransi.\")\n",
        "        break\n",
        "\n",
        "    previous_best_accuracy = best_accuracy\n",
        "\n",
        "# Final results output\n",
        "print(f'Nilai ccp_alpha terbaik: {best_alpha}, Accuracy: {best_accuracy:.3f}, F1 Score: {best_f1:.2f}')\n",
        "#ke fungsi RFC"
      ],
      "metadata": {
        "id": "Le6fLizfigZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi dengan teknik RFC\n",
        "final_model = RandomForestClassifier(random_state=50, ccp_alpha=best_alpha)\n",
        "final_model.fit(X_train, y_train)\n",
        "y_pred_final = final_model.predict(X_test)\n",
        "#Ke evaluasi"
      ],
      "metadata": {
        "id": "PrItSs5glrvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi melalui laporan dan 'confusion matrix'\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
        "class_report = classification_report(y_test, y_pred_final)\n",
        "#pencetakan nilai matriks\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "id": "yNvQCgi4l3Md"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan.\n",
        "### Rincian pemakaian algoritma KNN (K-nearest Neighboorhood)\n",
        "1. Persiapan numerisasi label **'onehotencoding'**\n",
        "2. Proses standardisasi kolom numerik dengan **\"Robustscaler\"**\n",
        "3. Eksekusi dengan teknik KNN melalui beberapa tahap :\n",
        "#### 3.a. Proses Pelatihan dan evaluasi nilai gama dalam jangkauan dinamis\n",
        "#### 3.b. Proses Paralelisasi untuk eksekusi dan evaluasi\n",
        "#### 3.c. Tahap pencetakan Nilai akurasi, presisi 'recall'\n",
        "### Rincian pemkaian algoritma RFC (Random Forest Classifier)\n",
        "* Persiapan numerisasi label dengan **'onehotencoding'**\n",
        "* proses standardisasi dengan metode sama (agar lebih adil)\n",
        "* Eksekusi fungsi yang terdiri dari\n",
        "** a. Pelatihan RFC dengan RandomSearch CV untuk modifikasi nanti\n",
        "** b. Tahapan paralelisasi untuk RFC\n",
        "** c. Tahap pencetakan nilai RFC"
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.\n",
        "\n",
        "## Evaluasi algoritma antara Hasil 'tetangga terdekat' dengan teknik 'randomforest'\n",
        "### Evaluasi dengan teknik KNN\n",
        "#### a. Hasil mengalmi fluktuasi rendah nilai akurasi presisi indeks 'recall' dan skor f1\n",
        "#### b.\n",
        "### Evaluasi dnegan teknik RFC\n",
        "#### 1. Nilai masih terlalu rendah baik tanpa pemberatan ataupun pembera"
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Bikx3LINv5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi di teknik KNN"
      ],
      "metadata": {
        "id": "26aTlch94foS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi grid search di SVM\n"
      ],
      "metadata": {
        "id": "OK0T2WS34lK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan di SVM\n"
      ],
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi RCT"
      ],
      "metadata": {
        "id": "5QFhKKQp4nWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal di RCT\n"
      ],
      "metadata": {
        "id": "Yr-zYpk156TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan di RCT"
      ],
      "metadata": {
        "id": "WQRB-bOs6Jsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ],
      "metadata": {
        "id": "feaPESoeN0zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode Support Vector Machine\n"
      ],
      "metadata": {
        "id": "ZApbldsp59T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode RandomForestClasifier\n"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    }
  ]
}