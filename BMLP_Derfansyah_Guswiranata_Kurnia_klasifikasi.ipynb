{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/cnkproject/blob/main/BMLP_Derfansyah_Guswiranata_Kurnia_klasifikasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan untuk pengelolaan data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Grafik\n",
        "import matplotlib.pyplot as plt #grafik dasar\n",
        "import seaborn as sns\n",
        "import datetime"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pelabelan untuk klasifikasi\n",
        "from sklearn.preprocessing import LabelBinarizer as lbina\n",
        "from sklearn.preprocessing import LabelEncoder as lenco"
      ],
      "metadata": {
        "id": "trwImvqYHw5-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian knn(p1)\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix as cmatr, classification_report\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler\n",
        "#jika pakai multilabel\n",
        "from sklearn.metrics import multilabel_confusion_matrix as mcmat"
      ],
      "metadata": {
        "id": "nJm5Mw1H3V6h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian klasifikasi 'randomforest'\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "syO5ZWQT00Op"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pengunduhan dataset ke google colab\n",
        "from google.colab import files\n",
        "#ke proses 'upload'"
      ],
      "metadata": {
        "id": "c7FAzF641Y18"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#proses 'upload'\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F_1zCMBK1aBp",
        "outputId": "fb05365a-f088-4496-f78b-8b6ea67ba8b5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e940649b-33bc-4c0a-97c0-1f4759b7e122\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e940649b-33bc-4c0a-97c0-1f4759b7e122\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hslclstr.csv to hslclstr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pengelolaan file\n",
        "import os #untuk os\n",
        "import time #waktu\n",
        "import datetime #tanggal\n",
        "import gc #pengunduhan file per batch"
      ],
      "metadata": {
        "id": "ndXvjNhh3ZaY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Penyimpanan hasil sementara di google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3iqu6N43l32",
        "outputId": "7c43305a-cc13-4318-fc77-d2847d498bce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inisiasi berat sampel\n",
        "from sklearn.utils.class_weight import compute_sample_weight as csw #inspeksi berat dl"
      ],
      "metadata": {
        "id": "3ePCGLMy0bhI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian multiprocessing melalui instalasi pool\n",
        "import warnings #peringatan\n",
        "import multiprocessing as mp #untuk multiprocessing\n",
        "from multiprocessing import Pool\n",
        "import joblib #Bagian Joblib"
      ],
      "metadata": {
        "id": "OxflnfjP3wry"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyimpanan hasil melalui dill\n",
        "! pip install dill\n",
        "import dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIIj64Qs3fIF",
        "outputId": "a059fb4a-702a-4eb7-e745-302bc775aa2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cek data\n",
        "df = pd.read_csv('/content/hslclstr.csv')\n",
        "dfc = df.copy() #jangan pakai data asli"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cek hasil\n",
        "smpl = dfc.head(7)\n",
        "inf = dfc.info() #informasi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3iFgini4lOP",
        "outputId": "9c1a5bbd-5c66-4a96-d7a0-f06f623fc08b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 16 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   img                          64016 non-null  object \n",
            " 1   title                        64016 non-null  object \n",
            " 2   console                      64016 non-null  object \n",
            " 3   genre                        64016 non-null  object \n",
            " 4   publisher                    64016 non-null  object \n",
            " 5   total_sales                  64016 non-null  float64\n",
            " 6   na_sales                     64016 non-null  float64\n",
            " 7   jp_sales                     64016 non-null  float64\n",
            " 8   pal_sales                    64016 non-null  float64\n",
            " 9   other_sales                  64016 non-null  float64\n",
            " 10  critic_score                 64016 non-null  float64\n",
            " 11  release_date                 64016 non-null  object \n",
            " 12  last_update                  64016 non-null  object \n",
            " 13  kemungkinan generasi         64016 non-null  int64  \n",
            " 14  kemungkinan jenis permainan  64016 non-null  int64  \n",
            " 15  Label                        64016 non-null  object \n",
            "dtypes: float64(6), int64(2), object(8)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi label untuk sampel\n",
        "lbl = dfc['Label'].copy()\n",
        "print(lbl.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49_-B54J5LvE",
        "outputId": "07cd93be-29de-4ea1-f2fb-d429fde6a4ed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    game kurang berkenan dengan fokus pencarian ke...\n",
            "1    game kurang berkenan dengan fokus pencarian ke...\n",
            "2    game kurang berkenan dengan fokus pencarian ke...\n",
            "3                game dengan tujuan utama pencari duit\n",
            "4    game kurang berkenan dengan fokus pencarian ke...\n",
            "5                game dengan tujuan utama pencari duit\n",
            "6                game dengan tujuan utama pencari duit\n",
            "Name: Label, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kolom ini menjadi basis sumbu y"
      ],
      "metadata": {
        "id": "b-xqdRyES5iM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi pembagian data\n",
        "inspk = dfc.iloc[:,5:11].copy() #numerikal untuk klasifikasi kluster\n",
        "inspk.info()"
      ],
      "metadata": {
        "id": "vM4BLUu_40kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97178090-efa0-4da1-ad60-0334749400af"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   total_sales   64016 non-null  float64\n",
            " 1   na_sales      64016 non-null  float64\n",
            " 2   jp_sales      64016 non-null  float64\n",
            " 3   pal_sales     64016 non-null  float64\n",
            " 4   other_sales   64016 non-null  float64\n",
            " 5   critic_score  64016 non-null  float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 2.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sumbu x\n",
        "xcls = inspk.copy() #pakai numerik"
      ],
      "metadata": {
        "id": "hdUVAumDGa2c"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumbu x  **(xcls)** adalah nilai numerikal dari tabel yang terdiri dari\n",
        "* Penjualan dari lima indikator (total, spesifika amerika utara, jepang, PAL, lain-lain)\n",
        "* Nilai kritik"
      ],
      "metadata": {
        "id": "lbtI-04vGloX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persiapan sumbu y"
      ],
      "metadata": {
        "id": "RqyAniQo-mKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numerisasi label (identifikasi jenis label)\n",
        "jnslbl = lbl.copy()\n",
        "jnslbl.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2klaS2KE7Ct",
        "outputId": "56cb9739-5eba-4086-f791-173395b815eb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Series name: Label\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "64016 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 500.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan pembagian data (untuk kluster)\n",
        "ycls = jnslbl #masih kata-kata\n",
        "#pelabelan dengan 'ohen.onehotencoder' (pembentukan ulang)\n",
        "bntkbaru, label = pd.factorize(ycls, sort=True, use_na_sentinel=False)\n",
        "#inspeksi hasil\n",
        "print(bntkbaru)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ea932ff-0a7c-49a2-de98-d39e5d02c7a0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 ... 1 1 1]\n",
            "Index(['game dengan tujuan utama pencari duit',\n",
            "       'game favortit dengan keuntungan rendah',\n",
            "       'game kurang berkenan dengan fokus pencarian keuntungan'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sampel kolom pelabelan"
      ],
      "metadata": {
        "id": "x8dr89b17Ii4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pembentukan ulang\n",
        "enkoding = bntkbaru.ravel()\n",
        "#inisiasi ohen\n",
        "encoder = lenco() #Untuk proses inti\n",
        "#penyesuaian data\n",
        "lblohen = encoder.fit_transform(enkoding)"
      ],
      "metadata": {
        "id": "GGwhIGqbIbPC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#konversi ke df untuk kluster jadi\n",
        "dflbl = pd.DataFrame(lblohen, columns=['Biner1'], copy=True)\n",
        "#cek hasil\n",
        "smpllbl = dflbl.head(7)\n",
        "tiplbl = dflbl.info()\n",
        "print(smpllbl) #inspeksi hasil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K6VVEnKJD6c",
        "outputId": "b75735c7-c2df-4d5e-fb07-dfae17b2c039"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 1 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   Biner1  64016 non-null  int64\n",
            "dtypes: int64(1)\n",
            "memory usage: 500.2 KB\n",
            "   Biner1\n",
            "0       2\n",
            "1       2\n",
            "2       2\n",
            "3       0\n",
            "4       2\n",
            "5       0\n",
            "6       0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai ini **(ycls)** menjadi komponen untuk penyatuan"
      ],
      "metadata": {
        "id": "eVozCln-JVYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#proses scaling untuk sumbu X (robust)\n",
        "rbsscal = RobustScaler(unit_variance=True) #untuk robust\n",
        "stdscal = StandardScaler() #untuk standar\n",
        "mmscal = MinMaxScaler(clip=True) #untuk indikator 'minmax'\n",
        "xclscl = rbsscal.fit_transform(xcls) #untuk tahap 1\n",
        "xclstd = stdscal.fit_transform(xclscl) #untuk tahap 2\n",
        "#pengubahan ke data frame untuk evaluasi\n",
        "dfxclstd = pd.DataFrame(xclstd, columns=xcls.columns,copy=True)"
      ],
      "metadata": {
        "id": "hCT3Q_vtT01z"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi kolom\n",
        "print(dfxclstd.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRuxkA5lUAvu",
        "outputId": "953c5100-7d5d-40ab-915f-623e50cd6275"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   total_sales   na_sales  jp_sales  pal_sales  other_sales  critic_score\n",
            "0    43.291200  25.764981  9.890744  52.679756    48.324018      1.518277\n",
            "1    41.299748  24.499722  5.872512  51.928485    46.769901      1.711821\n",
            "2    34.361784  34.091206  4.533102  29.283037    27.498858      1.647306\n",
            "3    33.740793  36.744169  0.308807  28.424442    21.904039      1.647306\n",
            "4    32.091956  24.989500  3.914912  32.288121    37.756026      0.679590\n",
            "5    31.513792  36.784984  1.030028  22.843574    20.505334      1.066677\n",
            "6    31.342484  39.601207  0.823965  19.838490    17.552513      1.131191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 kolom di dataframe 'dfxclstd' menjadi aspek **\"xclstd\"**"
      ],
      "metadata": {
        "id": "OSTrNylU4b6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deklarasi ycl\n",
        "ycl = dflbl.copy()"
      ],
      "metadata": {
        "id": "WcGMa0JZbLBv"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai salinan dflbl menjadi **'ycl'**"
      ],
      "metadata": {
        "id": "vucEDAEnA5VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deklarasi nilai X dan y\n",
        "X_train, X_test, y_train, y_test = train_test_split(xclstd, ycl, test_size=0.25, random_state=47, stratify=ycl) #untuk cek kondisi 1\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(xclstd, ycl, test_size=0.225, random_state=47, stratify=ycl) #untuk KOndisi 2"
      ],
      "metadata": {
        "id": "vOTh55sKJSZW"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Berat sampel di latihan\n",
        "brtsmplth = csw(class_weight='balanced', y=y_train) #dipakai di kondisi 1\n",
        "brtsmplth2 = csw(class_weight='balanced', y=y_train2) #dipakai di kondisi 2"
      ],
      "metadata": {
        "id": "V85NAqdUKA_Z"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi 'berat sampel' di data tes\n",
        "brtsampel = csw(class_weight='balanced', y=y_test) #dipakai di kondisi 1\n",
        "brtsampel2 = csw(class_weight='balanced', y=y_test2) #dipakai di kondisi 2"
      ],
      "metadata": {
        "id": "G4iGKOIz00Xg"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tujuan pemasan berat di latihan adalah penstabilan data dengan indisitas\n",
        "- Indisitas dengan '1' dan '2' menyatakan kondisi rasio"
      ],
      "metadata": {
        "id": "RYUgBI2SCcSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rincian Percobaan\n",
        "* Percobaan pertama untuk kedua metode berlangsung dengan rasio (3/1) (1)\n",
        "* Percobaan kedua dengan rasio (31/9)"
      ],
      "metadata": {
        "id": "V3pdLLjkPFeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi penentu akurasi melalui KNN\n",
        "def train_and_evaluate(k):\n",
        "    model = KNeighborsClassifier(n_neighbors=k, weights='distance', leaf_size=35,\n",
        "                                 metric='seuclidean',p=1,metric_params={'V': np.var(X_train, axis=0)})\n",
        "    #Tahap 'ravelisasi'\n",
        "    y_trainrav = y_train.values.ravel()\n",
        "    model.fit(X_train, y_trainrav)\n",
        "    #Prediksi\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Pembulatan metrik\n",
        "    accuracy = accuracy_score(y_test, y_pred, sample_weight=brtsampel) # Akurasi yang dinormalkan\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampel, zero_division=0) # Penyesuaian di presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted',sample_weight=brtsampel, zero_division=0) #Penyesuaian di kondisi recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted',sample_weight=brtsampel, zero_division=0) #Penyesuaian di skor F1\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Total Tetangga k={k}\")\n",
        "    print(f\"Nilai Akurasi: {accuracy:.4f}, Presisi: {precision:.4f}, Aspek Recall: {recall:.4f}, Skor F1: {f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(y_test, y_pred, sample_weight=brtsampel, zero_division=0)\n",
        "\n",
        "    if (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "       (accuracy >= 0.92 and precision >= 0.92 and recall >= 0.92 and f1 >= 0.92):\n",
        "        print(\"Hasil sangat bagus untuk disimpan bisa disimpan.\")\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "         (accuracy < 0.92 and precision < 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "        print(\"Hasil masih bisa disimpan.\")\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall < 0.87 and f1 < 0.87) or \\\n",
        "         (accuracy > 0.92 and precision > 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "         print(\"Ada masalah di recall dan nilai f1.\")\n",
        "         return None\n",
        "    else:\n",
        "        print(\"Hasil tidak pantas disimpan.\")\n",
        "        return None\n",
        "  #ke pembentukan matriks"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi evaluasi matriks\n",
        "def generate_confusion_matrix(y_true, y_pred, brtsampel):\n",
        "    cm = cmatr(y_true, y_pred, sample_weight=brtsampel, normalize='all') #Bisa matriks biasa atau multi matriks\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm_rounded = np.round(cm.astype(float), decimals=4)  # Pembulatan untuk kemudahan nilai\n",
        "    print(\"Hasil Confusion Matriks:\")\n",
        "    print(cm_rounded)\n",
        "    return cm_rounded\n",
        "#ke eksekusi asli"
      ],
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deklarasi parameter batas di KNN\n",
        "param_grid = range(340,350)\n",
        "#Paralelisasi melalui KNN\n",
        "if __name__ == '__main__':\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(train_and_evaluate, param_grid)\n",
        "\n",
        "    # Filter out empty results\n",
        "    filtered_results = [result for result in results if result is not None]\n",
        "\n",
        "    # Get the best result\n",
        "    best_result = max(filtered_results, key=lambda x: x[1], default=None)\n",
        "\n",
        "    if best_result:\n",
        "        # Pembulatans\n",
        "        rounded_best_result = (\n",
        "            best_result[0],  # Nilai awal\n",
        "            round(best_result[1], 3),  # Pembulatan 1\n",
        "            round(best_result[2], 3),  # Pembulatan 2\n",
        "            round(best_result[3], 3),  # Pembulatan 3\n",
        "            round(best_result[4], 3),  # Pembulatan 4\n",
        "            best_result[5],  # Predictions (y_pred)\n",
        "            best_result[6]   # Informasi tambahan\n",
        "        )\n",
        "\n",
        "        # Simpan nilai terbaik dari dill\n",
        "        with open('best_knn_result.dill', 'wb') as f:\n",
        "            dill.dump(rounded_best_result, f)\n",
        "\n",
        "        _, _, _, _, _, y_pred, _ = rounded_best_result\n",
        "        cm = generate_confusion_matrix(y_test, y_pred, brtsampel)\n",
        "\n",
        "        # Simpan hasil matriks terbaik saja\n",
        "        with open('best_confusion_matrix.dill', 'wb') as cm_file:\n",
        "            dill.dump(cm, cm_file)\n",
        "\n",
        "        # Print the best rounded result\n",
        "        print(\"Best Result:\", rounded_best_result)\n",
        "#eksekusi KNN"
      ],
      "metadata": {
        "id": "VOTaGStgLZd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c63972-fbac-4ef6-b413-1fb9f76f1bc8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Tetangga k=342\n",
            "Nilai Akurasi: 0.4282, Presisi: 0.4374, Aspek Recall: 0.4282, Skor F1: 0.4101\n",
            "Total Tetangga k=340\n",
            "Nilai Akurasi: 0.4284, Presisi: 0.4377, Aspek Recall: 0.4284, Skor F1: 0.4104\n",
            "Hasil masih bisa disimpan.\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=341\n",
            "Nilai Akurasi: 0.4284, Presisi: 0.4377, Aspek Recall: 0.4284, Skor F1: 0.4104\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=343\n",
            "Nilai Akurasi: 0.4285, Presisi: 0.4378, Aspek Recall: 0.4285, Skor F1: 0.4104\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=344\n",
            "Nilai Akurasi: 0.4284, Presisi: 0.4377, Aspek Recall: 0.4284, Skor F1: 0.4104\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=346\n",
            "Nilai Akurasi: 0.4282, Presisi: 0.4373, Aspek Recall: 0.4282, Skor F1: 0.4101\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=345\n",
            "Nilai Akurasi: 0.4283, Presisi: 0.4375, Aspek Recall: 0.4283, Skor F1: 0.4103\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=347\n",
            "Nilai Akurasi: 0.4282, Presisi: 0.4375, Aspek Recall: 0.4282, Skor F1: 0.4102\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=348\n",
            "Nilai Akurasi: 0.4282, Presisi: 0.4373, Aspek Recall: 0.4282, Skor F1: 0.4101\n",
            "Hasil masih bisa disimpan.\n",
            "Total Tetangga k=349\n",
            "Nilai Akurasi: 0.4283, Presisi: 0.4375, Aspek Recall: 0.4283, Skor F1: 0.4102\n",
            "Hasil masih bisa disimpan.\n",
            "Confusion Matrix:\n",
            "Hasil Confusion Matriks:\n",
            "[[0.2205 0.0703 0.0425]\n",
            " [0.1571 0.1298 0.0465]\n",
            " [0.154  0.1011 0.0782]]\n",
            "Best Result: (343, 0.428, 0.438, 0.428, 0.41, array([0, 0, 1, ..., 1, 0, 0]), '              precision    recall  f1-score   support\\n\\n           0       0.41      0.66      0.51 5334.666666666284\\n           1       0.43      0.39      0.41 5334.666666666843\\n           2       0.47      0.23      0.31 5334.666666666667\\n\\n    accuracy                           0.43 16003.999999999796\\n   macro avg       0.44      0.43      0.41 16003.999999999796\\nweighted avg       0.44      0.43      0.41 16003.999999999796\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap pertama RFC (pelacakan nilai ccp alpha)\n",
        "nialpf = np.arange(1.75e-4, 0.175, 1.75e-4) #Nilai alfa\n",
        "itmaks = 420\n",
        "tolerance = 1.8e-4\n",
        "best_alpha = None\n",
        "best_accuracy = -np.inf\n",
        "best_f1 = -np.inf\n",
        "previous_best_accuracy = None\n",
        "#ke deklarasi berat sampel"
      ],
      "metadata": {
        "id": "povKRBbsg_hI"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi joblib\n",
        "filename = '/tmp/dataset.joblib'\n",
        "joblib.dump(np.asfortranarray(X_train), filename)\n",
        "X_train_mmap = joblib.load(filename, mmap_mode='r')"
      ],
      "metadata": {
        "id": "0K-RqmQu5mZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan berat sampel\n",
        "klsbrt = np.unique(y_train) #kelas berat di RFC\n",
        "brtsmplth = csw(class_weight='balanced', y=y_train) #nilai deklarasi\n",
        "dictbrt = dict(zip(klsbrt, brtsmplth)) #dideklarasikan sebagai kampus"
      ],
      "metadata": {
        "id": "rvQMj-nQ5QB9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi inspeksi nilai ccp alpha optimal\n",
        "def evaluasi_alfa(alpha):\n",
        "    rfc = RandomForestClassifier(n_estimators=121, max_depth=8, n_jobs=3,random_state=50, ccp_alpha=alpha, class_weight=dictbrt ,warm_start=True)\n",
        "    #Perataan menjadi satu dimensi\n",
        "    y_trainr = y_train.values.ravel()\n",
        "\n",
        "    rfc.fit(X_train_mmap, y_trainr, sample_weight=brtsmplth)\n",
        "\n",
        "    y_pred = rfc.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Pembulatan akurasi\n",
        "    accuracy_rounded = round(accuracy, 3)\n",
        "    # Penghindaran Peringatan di normalisasi\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', sample_weight=brtsampel, zero_division=0)  # Nilai f1\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampel, zero_division=0)  # indikator presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', sample_weight=brtsampel, zero_division=0)  # Nilai Recall\n",
        "\n",
        "    return alpha, accuracy_rounded, f1, precision, recall  # Return values\n",
        "\n",
        "# Iterasi melalui jangkauan nilai alfa\n",
        "for iteration in range(itmaks):\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(evaluasi_alfa, nialpf)\n",
        "\n",
        "    for alpha, accuracy, f1, precision, recall in results:\n",
        "        if accuracy > best_accuracy or (accuracy == best_accuracy and f1 > best_f1):\n",
        "            best_alpha = alpha\n",
        "            best_accuracy = accuracy\n",
        "            best_f1 = f1\n",
        "\n",
        "        # Pemeriksaan untuk nilai minimal (atau optimal)\n",
        "        if (accuracy >= 0.92 and precision >= 0.92 and\n",
        "            recall >= 0.92 and f1 >= 0.92) or \\\n",
        "           (accuracy >= 0.87 and precision >= 0.87 and\n",
        "            recall >= 0.87 and f1 >= 0.87):\n",
        "            print(f\"Optimal metrics reached with ccp_alpha: {alpha}, \"\n",
        "                  f\"Akurasi: {accuracy:.3f}, F1 Score: {f1:.2f}, \"\n",
        "                  f\"Precision: {precision:.2f}, Recall: {recall:.2f}. Stopping search.\")\n",
        "            break\n",
        "\n",
        "    # Pengaturan Nilai alfa\n",
        "    nialpf = np.linspace(max(0.001, best_alpha - 0.005), min(0.1, best_alpha + 0.005), num=10)\n",
        "\n",
        "    # Check for tolerance to stop early\n",
        "    if iteration > 0 and abs(best_accuracy - previous_best_accuracy) < tolerance:\n",
        "        print(\"Penghentian terjadi karena sudah melewati batas toleransi.\")\n",
        "        break\n",
        "\n",
        "    previous_best_accuracy = best_accuracy\n",
        "\n",
        "# Final results output\n",
        "print(f'Nilai ccp_alpha terbaik: {best_alpha}, Accuracy: {best_accuracy:.3f}, F1 Score: {best_f1:.2f}')\n",
        "#ke fungsi RFC"
      ],
      "metadata": {
        "id": "Le6fLizfigZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap Perhitungan\n",
        "final_model = RandomForestClassifier(random_state=50, ccp_alpha=best_alpha, class_weight=brtsmplth ,warm_start=True)\n",
        "final_model.fit(X_train_mmap, y_train, sample_weight=brtsmplth)\n",
        "y_pred_final = final_model.predict(X_test)\n",
        "#Ke evaluasi"
      ],
      "metadata": {
        "id": "PrItSs5glrvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi melalui laporan dan 'confusion matrix'\n",
        "conf_matrix = cmatr(y_test, y_pred_final, sample_weight=brtsampel, normalize='all')\n",
        "class_report = classification_report(y_test, y_pred_final, sample_weight=brtsampel, zero_division=0)\n",
        "#pencetakan nilai matriks\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNvQCgi4l3Md",
        "outputId": "a6f57c15-16b5-4763-b439-224e371ec6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[3811 1301  763]\n",
            " [2103 2396  787]\n",
            " [2008 1509 1326]]\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "                                                        precision    recall  f1-score   support\n",
            "\n",
            "                 game dengan tujuan utama pencari duit       0.48      0.65      0.55      5875\n",
            "                game favortit dengan keuntungan rendah       0.46      0.45      0.46      5286\n",
            "game kurang berkenan dengan fokus pencarian keuntungan       0.46      0.27      0.34      4843\n",
            "\n",
            "                                              accuracy                           0.47     16004\n",
            "                                             macro avg       0.47      0.46      0.45     16004\n",
            "                                          weighted avg       0.47      0.47      0.46     16004\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan.\n",
        "### Rincian pemakaian algoritma KNN (K-nearest Neighboorhood)\n",
        "1. Persiapan numerisasi label **'labelencoder'**\n",
        "2. Proses standardisasi kolom numerik dengan **\"Robustscaler\",\"Standard Scaler\", dan \"Minmax Scaler\"**\n",
        "3. Eksekusi dengan teknik KNN melalui beberapa tahap :\n",
        "#### 3.a. Proses Penentuan parameter di metode K-nearestNeighborhood dengan pemberat di data latihan\n",
        "#### 3.b. Proses Paralelisasi untuk eksekusi dan evaluasi\n",
        "#### 3.c. Tahap pencetakan Nilai akurasi, presisi, 'recall', dan skor f1\n",
        "### Rincian pemkaian algoritma RFC (Random Forest Classifier)\n",
        "* Persiapan numerisasi label dengan **'onehotencoding'**\n",
        "* proses standardisasi dengan metode sama (agar lebih adil)\n",
        "* Eksekusi fungsi yang terdiri dari\n",
        "** a. Pelatihan RFC dengan RandomSearch CV untuk modifikasi nanti\n",
        "** b. Tahapan paralelisasi untuk RFC\n",
        "** c. Tahap pencetakan nilai RFC"
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.\n",
        "\n",
        "## Evaluasi algoritma antara Hasil 'tetangga terdekat' dengan teknik 'randomforest'\n",
        "### Evaluasi dengan teknik KNN\n",
        "#### 1. Hasil mengalmi fluktuasi rendah nilai akurasi presisi indeks 'recall' dan skor f1\n",
        "#### 2. Nilai masih belum mencapai akurasi minimal walau nilai dipasang pemberat\n",
        "#### 3.  \n",
        "### Evaluasi dnegan teknik RFC\n",
        "#### a. Nilai masih terlalu rendah baik tanpa pemberatan ataupun pemberatan\n",
        "#### b."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Bikx3LINv5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi di teknik KNN"
      ],
      "metadata": {
        "id": "26aTlch94foS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi grid search di KNN\n",
        "def tuned_train_and_evaluate(X_train, y_train, X_test, y_test, brtsampel):\n",
        "  # Definisikan nilai sampel\n",
        "    knn = KNeighborsClassifier(weights='distance', leaf_size=35,\n",
        "                                 metric='seuclidean',verbose=1,p=1,metric_params={'V': np.var(X_train, axis=0)})\n",
        "\n",
        "    # Definisi pemberat dalam parameter\n",
        "    brtsmplth = csw(class_weight='balanced', y=y_train)\n",
        "    #eksekusi parameter\n",
        "    param_dist = {\n",
        "        'n_neighbors': range(250, 260),  # Penyetelan\n",
        "        'weights': ['uniform', brtsmplth],\n",
        "        'metric': ['seuclidean', 'cosine']\n",
        "    }\n",
        "\n",
        "    # Initialize RandomizedSearchCV\n",
        "    random_search = RandomizedSearchCV(knn, param_distributions=param_dist, verbose=1,n_iter=20, cv=5, random_state=42)\n",
        "\n",
        "    # Penyesuaian model dengan kondisi tertentu\n",
        "    random_search.fit(X_train, y_train) #Modifikasi Joblib\n",
        "\n",
        "    # Prediksi model terbaik\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Pembulatan metrik\n",
        "    accuracy = accuracy_score(y_test, y_pred, sample_weight=brtsampel)  # Akurasi yang dinormalkan\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di kondisi recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di skor F1\n",
        "\n",
        "    # Cetak Metrik\n",
        "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "    print(f\"Nilai Akurasi: {accuracy:.4f}, Presisi: {precision:.4f}, Aspek Recall: {recall:.4f}, Skor F1: {f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    if (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "       (accuracy >= 0.92 and precision >= 0.92 and recall >= 0.92 and f1 >= 0.92):\n",
        "        return (random_search.best_params_['n_neighbors'], accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "         (accuracy < 0.92 and precision < 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "        print(\"Hasil masih bisa disimpan.\")\n",
        "        return (random_search.best_params_['n_neighbors'], accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall < 0.87 and f1 < 0.87) or \\\n",
        "         (accuracy > 0.92 and precision > 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "         print(\"Ada masalah di recall dan nilai f1.\")\n",
        "         return None\n",
        "    else:\n",
        "        print(\"Hasil tidak pantas disimpan.\")\n",
        "        return None\n",
        "  #ke tuning lanjutan"
      ],
      "metadata": {
        "id": "OK0T2WS34lK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan tuning di KNN (matriks)\n",
        "def tuned_confusion_matrix(y_true, y_pred):\n",
        "    cm = cmatr(y_true, y_pred,sample_weight=brtsampel, normalize='all')\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm_rounded = np.round(cm.astype(float), decimals=4)  # Pembulatan untuk kemudahan nilai\n",
        "    print(\"Hasil Confusion Matriks:\")\n",
        "    print(cm_rounded)\n",
        "    return cm_rounded\n",
        "#ke eksekusi akhir"
      ],
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eksekusi dengan Randomized search\n",
        "if __name__ == '__main__':\n",
        "    # Definisi pemberatan\n",
        "    result = tuned_train_and_evaluate(X_train, y_train, X_test, y_test, brtsampel)\n",
        "\n",
        "    if result:\n",
        "        k_value = result[0]\n",
        "        rounded_results = tuple(round(x, 3) if isinstance(x, float) else x for x in result)\n",
        "\n",
        "        # Simpan nilai terbaik dari dill\n",
        "        with open('tuned_knn_result.dill', 'wb') as f:\n",
        "            dill.dump(rounded_results, f)\n",
        "\n",
        "        _, _, _, _, _, y_pred, _ = rounded_results\n",
        "        cm2 = generate_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Simpan hasil matriks terbaik saja\n",
        "        with open('tuned_confusion_matrix.dill', 'wb') as cm_file:\n",
        "            dill.dump(cm2, cm_file)\n",
        "\n",
        "        # Print the best rounded result\n",
        "        print(\"Best Result:\", rounded_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMyTCQctRbN-",
        "outputId": "5336aeed-6ced-4d3d-dcea-008d083bfff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'weights': 'distance', 'n_neighbors': 198, 'metric': 'manhattan'}\n",
            "Nilai Akurasi: 0.4387, Presisi: 0.4443, Aspek Recall: 0.4387, Skor F1: 0.4244\n",
            "Hasil masih bisa disimpan.\n",
            "Confusion Matrix:\n",
            "Hasil Confusion Matriks:\n",
            "[[3383.3137 1222.2062  729.1468]\n",
            " [2211.1719 2291.9084  831.5863]\n",
            " [2325.311  1663.2969 1346.0588]]\n",
            "Best Result: (198, 0.439, 0.444, 0.439, 0.424, array(['game favortit dengan keuntungan rendah',\n",
            "       'game kurang berkenan dengan fokus pencarian keuntungan',\n",
            "       'game favortit dengan keuntungan rendah', ...,\n",
            "       'game dengan tujuan utama pencari duit',\n",
            "       'game favortit dengan keuntungan rendah',\n",
            "       'game dengan tujuan utama pencari duit'], dtype=object), '                                                        precision    recall  f1-score   support\\n\\n                 game dengan tujuan utama pencari duit       0.46      0.63      0.54      5875\\n                game favortit dengan keuntungan rendah       0.44      0.43      0.44      5286\\ngame kurang berkenan dengan fokus pencarian keuntungan       0.43      0.25      0.32      4843\\n\\n                                              accuracy                           0.45     16004\\n                                             macro avg       0.45      0.44      0.43     16004\\n                                          weighted avg       0.45      0.45      0.44     16004\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aspek modifikasi:\n",
        "1. Implementasi dua metode pemberat (seuclidian dan nilai parameter 'brtsmplth')\n",
        "2. Nilai cosine bertujuan untuk inspeksi sudut"
      ],
      "metadata": {
        "id": "DH54qbjKsSrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi metode RFC"
      ],
      "metadata": {
        "id": "5QFhKKQp4nWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal di RCT (deklarasi parameter)\n",
        "rcfparam = {'ccp_alpha': np.arange(1.75e-4, 0.175, 1.75e-4),'estimator':[100, 150, 200],\n",
        "            'max_depth':[1,10,20,30],'min_samples_split': [2, 5, 10],'class_weight': ['balanced', brtsmplth]} #Parameter"
      ],
      "metadata": {
        "id": "Yr-zYpk156TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan di RCT (Fungsi)\n",
        "def rfc_randomized(X_train, y_train):\n",
        "#Persiapan berat sampel\n",
        "    klsbrt = np.unique(y_train) #kelas berat di RFC\n",
        "    brtsmplth = csw(class_weight='balanced', y=y_train) #nilai deklarasi\n",
        "    dictbrt = dict(zip(klsbrt, brtsmplth)) #dideklarasikan sebagai kampus\n",
        "    #Inisiasi rfc dalam randomized\n",
        "    rfc2 = RandomForestClassifier(random_state=50, class_weight=dictbrt ,warm_start=True, verbose=1)\n",
        "    #Penyetelan Randomsearch CV\n",
        "    random_search = RandomizedSearchCV(estimator=rfc2, param_distributions=rcfparam,\n",
        "                                       n_iter=100,scoring='f1_weighted',\n",
        "                                       cv=6, verbose=2,\n",
        "                                       random_state=42,\n",
        "                                       n_jobs=-1)\n",
        "  #ke persiapan verbose"
      ],
      "metadata": {
        "id": "WQRB-bOs6Jsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pemangilan hasil\n",
        "randmod , randparam = rfc_randomized(X_train_mmap, y_train)\n",
        "#Prediksi dengan randomized search\n",
        "ypred_rnd = randmod.predict(X_test)\n",
        "#Evaluasi hasil randomizedsearch melalui matriks dan laporan\n",
        "cmatrand = cmatr(y_test, y_pred_final, sample_weight=brtsampel, normalize='all') #pasca modifikasi\n",
        "laporan = classification_report(y_test, y_pred_final, sample_weight=brtsampel, zero_division=0)\n",
        "\n",
        "# Print results\n",
        "print(f'Best Parameters: {randmod}')\n",
        "print(\"Inspeksi Matriks Kebingungan:\")\n",
        "print(cmatrand)\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(laporan)"
      ],
      "metadata": {
        "id": "z7IgV0hHpw1P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ],
      "metadata": {
        "id": "feaPESoeN0zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode K-NearestNeighborhood (Normal)\n",
        "hslcmatk = cm #Hasil dari K-Nearest Neighborhood\n",
        "hslcmatr = conf_matrix #Hasil dari Randomforest classifier"
      ],
      "metadata": {
        "id": "ZApbldsp59T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Modifikasi Randomizedsearch CV\n",
        "hslmoda = cm2 #Hasil dari Randomizedsearch CV untuk K-nearest\n",
        "hslmodb = cmatrand #Hasil dari Randomizedsearch CV untuk RFC\n",
        "#ke ilustrasi matriks"
      ],
      "metadata": {
        "id": "rDwI7b1ryuwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi metode 'KNN' melalui ilustrasi matriks (normal)\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(hslcmatk, annot=True, fmt='.4f', cmap='Blues',\n",
        "            xticklabels=['Kelas 1', 'Kelas 2', 'Kelas 3'],  # Adjust according to your classes\n",
        "            yticklabels=['Kelas 1', 'Kelas 2', 'Kelas 3'])  # Adjust according to your classes\n",
        "plt.ylabel('Label sesungguhnya')\n",
        "plt.xlabel('Label terprediksi')\n",
        "plt.title('Inspeksi Matrik melalui metode KNN')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wwjyxMHf1OJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dengan modifikasi 'RandomizedsearchCV'\n"
      ],
      "metadata": {
        "id": "dWjAbZHx1fs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode RandomForestClasifier\n"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    }
  ]
}