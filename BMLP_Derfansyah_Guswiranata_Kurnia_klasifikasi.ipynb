{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DGkurnia/cnkproject/blob/main/BMLP_Derfansyah_Guswiranata_Kurnia_klasifikasi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pada tahap ini, Anda perlu mengimpor beberapa pustaka (library) Python yang dibutuhkan untuk analisis data dan pembangunan model machine learning."
      ],
      "metadata": {
        "id": "LgA3ERnVn84N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perpustakaan untuk pengelolaan data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#Grafik\n",
        "import matplotlib.pyplot as plt #grafik dasar\n",
        "import seaborn as sns\n",
        "import datetime"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pelabelan untuk 'onehotencoder'\n",
        "from sklearn.preprocessing import MultiLabelBinarizer as mlbi"
      ],
      "metadata": {
        "id": "trwImvqYHw5-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian svm(p1)\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "from sklearn.preprocessing import RobustScaler, MinMaxScaler, StandardScaler"
      ],
      "metadata": {
        "id": "nJm5Mw1H3V6h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian klasifikasi 'randomforest'\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "syO5ZWQT00Op"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pengunduhan dataset ke google colab\n",
        "from google.colab import files\n",
        "#ke proses 'upload'"
      ],
      "metadata": {
        "id": "c7FAzF641Y18"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#proses 'upload'\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "F_1zCMBK1aBp",
        "outputId": "00cf35dc-ef8e-4557-83f6-0527b9825147"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b7aa1c42-b636-4ba4-9f87-963edcc24fd4\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b7aa1c42-b636-4ba4-9f87-963edcc24fd4\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving hslclstr.csv to hslclstr.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pengelolaan file\n",
        "import os #untuk os\n",
        "import time #waktu\n",
        "import datetime #tanggal\n",
        "import gc #pengunduhan file per batch"
      ],
      "metadata": {
        "id": "ndXvjNhh3ZaY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Penyimpanan hasil sementara di google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3iqu6N43l32",
        "outputId": "8a6abb77-2ee9-4e11-9e9a-0e83ef69e96c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inisiasi berat sampel\n",
        "from sklearn.utils.class_weight import compute_sample_weight as csw #inspeksi berat dl"
      ],
      "metadata": {
        "id": "3ePCGLMy0bhI"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Bagian multiprocessing melalui instalasi pool\n",
        "import warnings #peringatan\n",
        "import multiprocessing as mp #untuk multiprocessing\n",
        "from multiprocessing import Pool"
      ],
      "metadata": {
        "id": "OxflnfjP3wry"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#penyimpanan hasil melalui dill\n",
        "! pip install dill\n",
        "import dill"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIIj64Qs3fIF",
        "outputId": "bc8e8311-55de-48e5-b077-401b8ea6888b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dill\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dill\n",
            "Successfully installed dill-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Memuat Dataset dari Hasil Clustering**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memuat dataset hasil clustering dari file CSV ke dalam variabel DataFrame."
      ],
      "metadata": {
        "id": "Ey3ItwTen_7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cek data\n",
        "df = pd.read_csv('/content/hslclstr.csv')\n",
        "dfc = df.copy() #jangan pakai data asli"
      ],
      "metadata": {
        "id": "GHCGNTyrM5fS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cek hasil\n",
        "smpl = dfc.head(7)\n",
        "inf = dfc.info() #informasi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3iFgini4lOP",
        "outputId": "905d298d-dc03-499b-bf6e-89fd5817bb2d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 16 columns):\n",
            " #   Column                       Non-Null Count  Dtype  \n",
            "---  ------                       --------------  -----  \n",
            " 0   img                          64016 non-null  object \n",
            " 1   title                        64016 non-null  object \n",
            " 2   console                      64016 non-null  object \n",
            " 3   genre                        64016 non-null  object \n",
            " 4   publisher                    64016 non-null  object \n",
            " 5   total_sales                  64016 non-null  float64\n",
            " 6   na_sales                     64016 non-null  float64\n",
            " 7   jp_sales                     64016 non-null  float64\n",
            " 8   pal_sales                    64016 non-null  float64\n",
            " 9   other_sales                  64016 non-null  float64\n",
            " 10  critic_score                 64016 non-null  float64\n",
            " 11  release_date                 64016 non-null  object \n",
            " 12  last_update                  64016 non-null  object \n",
            " 13  kemungkinan generasi         64016 non-null  int64  \n",
            " 14  kemungkinan jenis permainan  64016 non-null  int64  \n",
            " 15  Label                        64016 non-null  object \n",
            "dtypes: float64(6), int64(2), object(8)\n",
            "memory usage: 7.8+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi label untuk sampel\n",
        "lbl = dfc['Label'].copy()\n",
        "print(lbl.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49_-B54J5LvE",
        "outputId": "965684ea-9159-4b3c-b4a7-983b08cb30a9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    game kurang berkenan dengan fokus pencarian ke...\n",
            "1    game kurang berkenan dengan fokus pencarian ke...\n",
            "2    game kurang berkenan dengan fokus pencarian ke...\n",
            "3                game dengan tujuan utama pencari duit\n",
            "4    game kurang berkenan dengan fokus pencarian ke...\n",
            "5                game dengan tujuan utama pencari duit\n",
            "6                game dengan tujuan utama pencari duit\n",
            "Name: Label, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Data Splitting**"
      ],
      "metadata": {
        "id": "KkPem5eWL2UP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tahap Data Splitting bertujuan untuk memisahkan dataset menjadi dua bagian: data latih (training set) dan data uji (test set)."
      ],
      "metadata": {
        "id": "YYj1rl_JNI9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi pembagian data\n",
        "inspk = dfc.iloc[:,5:11].copy() #numerikal untuk klasifikasi kluster\n",
        "inspk.info()"
      ],
      "metadata": {
        "id": "vM4BLUu_40kl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea0ae6b-e5a5-499e-ea52-545ac595842f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 6 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   total_sales   64016 non-null  float64\n",
            " 1   na_sales      64016 non-null  float64\n",
            " 2   jp_sales      64016 non-null  float64\n",
            " 3   pal_sales     64016 non-null  float64\n",
            " 4   other_sales   64016 non-null  float64\n",
            " 5   critic_score  64016 non-null  float64\n",
            "dtypes: float64(6)\n",
            "memory usage: 2.9 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Sumbu x\n",
        "xcls = inspk.copy() #pakai numerik"
      ],
      "metadata": {
        "id": "hdUVAumDGa2c"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sumbu x  **(xcls)** adalah nilai numerikal dari tabel yang terdiri dari\n",
        "* Penjualan dari lima indikator (total, spesifika amerika utara, jepang, PAL, lain-lain)\n",
        "* Nilai kritik"
      ],
      "metadata": {
        "id": "lbtI-04vGloX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persiapan sumbu y"
      ],
      "metadata": {
        "id": "RqyAniQo-mKa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#numerisasi label (identifikasi jenis label)\n",
        "jnslbl = dfc['Label'].copy()\n",
        "jnslbl.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2klaS2KE7Ct",
        "outputId": "50a8e79c-c3c9-4076-80b1-cec7bd4b7133"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Series name: Label\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "64016 non-null  object\n",
            "dtypes: object(1)\n",
            "memory usage: 500.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Persiapan pembagian data (untuk kluster)\n",
        "ycls = jnslbl #masih kata-kata\n",
        "#pelabelan dengan 'ohen.onehotencoder' (pembentukan ulang)\n",
        "bntkbaru, label = pd.factorize(ycls, sort=True, use_na_sentinel=False)\n",
        "#inspeksi hasil\n",
        "print(bntkbaru)\n",
        "print(label)"
      ],
      "metadata": {
        "id": "OubAW-7ONKVj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "331950c3-ffa1-4496-cb47-e1fd9feaa41b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 ... 1 1 1]\n",
            "Index(['game dengan tujuan utama pencari duit',\n",
            "       'game favortit dengan keuntungan rendah',\n",
            "       'game kurang berkenan dengan fokus pencarian keuntungan'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sampel kolom pelabelan"
      ],
      "metadata": {
        "id": "x8dr89b17Ii4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pembentukan ulang\n",
        "enkoding = bntkbaru.reshape(-1,1)\n",
        "#inisiasi ohen\n",
        "encoder = mlbi(sparse_output=False) #Untuk\n",
        "#penyesuaian data\n",
        "lblohen = encoder.fit_transform(enkoding)"
      ],
      "metadata": {
        "id": "GGwhIGqbIbPC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#konversi ke df untuk kluster jadi\n",
        "dflbl = pd.DataFrame(lblohen, columns=['Biner1','Biner2','Biner3'])\n",
        "#cek hasil\n",
        "smpllbl = dflbl.head(7)\n",
        "tiplbl = dflbl.info()\n",
        "print(tiplbl) #inspeksi hasil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-K6VVEnKJD6c",
        "outputId": "13349757-08c0-44b4-beec-67a92545a6ed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 64016 entries, 0 to 64015\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype\n",
            "---  ------  --------------  -----\n",
            " 0   Biner1  64016 non-null  int64\n",
            " 1   Biner2  64016 non-null  int64\n",
            " 2   Biner3  64016 non-null  int64\n",
            "dtypes: int64(3)\n",
            "memory usage: 1.5 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai ini **(ycls)** menjadi komponen untuk penyatuan"
      ],
      "metadata": {
        "id": "eVozCln-JVYn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Membangun Model Klasifikasi**\n"
      ],
      "metadata": {
        "id": "IVPbB03CMhTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **a. Membangun Model Klasifikasi**"
      ],
      "metadata": {
        "id": "Ned1pL9zMmBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setelah memilih algoritma klasifikasi yang sesuai, langkah selanjutnya adalah melatih model menggunakan data latih.\n",
        "\n",
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Pilih algoritma klasifikasi yang sesuai, seperti Logistic Regression, Decision Tree, Random Forest, atau K-Nearest Neighbors (KNN).\n",
        "2. Latih model menggunakan data latih."
      ],
      "metadata": {
        "id": "WAWzPOE4Nkti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#proses scaling untuk sumbu X (robust)\n",
        "rbsscal = RobustScaler(unit_variance=True) #untuk robust\n",
        "stdscal = StandardScaler() #untuk standar\n",
        "mmscal = MinMaxScaler(clip=True) #untuk indikator 'minmax'\n",
        "xclscl = rbsscal.fit_transform(xcls) #untuk tahap 1\n",
        "xclstd = stdscal.fit_transform(xclscl) #untuk tahap 2\n",
        "#pengubahan ke data frame untuk evaluasi\n",
        "dfxclstd = pd.DataFrame(xclstd, columns=xcls.columns,copy=True)"
      ],
      "metadata": {
        "id": "hCT3Q_vtT01z"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#inspeksi kolom\n",
        "print(dfxclstd.head(7))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRuxkA5lUAvu",
        "outputId": "f6804df5-58b6-4eed-e1bb-60f96da42af2"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   total_sales   na_sales  jp_sales  pal_sales  other_sales  critic_score\n",
            "0    43.291200  25.764981  9.890744  52.679756    48.324018      1.518277\n",
            "1    41.299748  24.499722  5.872512  51.928485    46.769901      1.711821\n",
            "2    34.361784  34.091206  4.533102  29.283037    27.498858      1.647306\n",
            "3    33.740793  36.744169  0.308807  28.424442    21.904039      1.647306\n",
            "4    32.091956  24.989500  3.914912  32.288121    37.756026      0.679590\n",
            "5    31.513792  36.784984  1.030028  22.843574    20.505334      1.066677\n",
            "6    31.342484  39.601207  0.823965  19.838490    17.552513      1.131191\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6 kolom di dataframe 'dfxclstd' menjadi aspek **\"xclstd\"**"
      ],
      "metadata": {
        "id": "OSTrNylU4b6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deklarasi ycl\n",
        "ycl = dflbl.copy()"
      ],
      "metadata": {
        "id": "WcGMa0JZbLBv"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nilai salinan dflbl menjadi **'ycl'**"
      ],
      "metadata": {
        "id": "vucEDAEnA5VH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#deklarasi nilai X dan y\n",
        "X_train, X_test, y_train, y_test = train_test_split(xclstd, ycl, test_size=0.25, random_state=42, stratify=ycl) #untuk cek kondisi 1\n",
        "X_train2, X_test2, y_train2, y_test2 = train_test_split(xclstd, ycl, test_size=0.225, random_state=42, stratify=ycl) #untuk KOndisi 2"
      ],
      "metadata": {
        "id": "vOTh55sKJSZW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Berat sampel di latihan\n",
        "brtsmplth = csw(class_weight='balanced', y=y_train) #dipakai di kondisi 1\n",
        "brtsmplth2 = csw(class_weight='balanced', y=y_train2) #dipakai di kondisi 2"
      ],
      "metadata": {
        "id": "V85NAqdUKA_Z"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi 'berat sampel' di data tes\n",
        "brtsampel = csw(class_weight='balanced', y=y_test) #dipakai di kondisi 1\n",
        "brtsampel2 = csw(class_weight='balanced', y=y_test2) #dipakai di kondisi 2"
      ],
      "metadata": {
        "id": "G4iGKOIz00Xg"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi indesitas (latihan)\n",
        "indcilth = np.arange(len(brtsmplth)) #Latihan di kondisi 1\n",
        "indcilth2 = np.arange(len(brtsmplth2)) #Latihan di kondisi 2\n",
        "#di bagian tes\n",
        "indcites = np.arange(len(brtsampel)) #Tes di kondisi 1\n",
        "indcites2 = np.arange(len(brtsampel2)) #Tes di kondisi 2\n",
        "#probabilitas berat (Latihan)\n",
        "plth = brtsmplth[indcilth] / brtsmplth.sum() #Latihan di kondisi 1\n",
        "plth2 = brtsmplth2[indcilth2] / brtsmplth2.sum() #Latihan di kondisi 2\n",
        "#di bagian tes\n",
        "ptes = brtsampel[indcites] / brtsampel.sum() #Tes di kondisi 1\n",
        "ptes2 = brtsampel2[indcites2] / brtsampel2.sum() #Tes di kondisi 2"
      ],
      "metadata": {
        "id": "gbopgWxIDZSZ"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Penyetelan indesitas (latihan)\n",
        "brtindlth1 = np.random.choice(indcilth, size=len(brtsmplth), p=plth, replace=True) #Kondisi 1\n",
        "brtindlth2 = np.random.choice(indcilth2, size=len(brtsmplth2), p=plth2, replace=True) #Kondisi 2\n",
        "#Penyetelan di data tes\n",
        "brtindtes1 = np.random.choice(indcites, size=len(brtsampel), p=ptes, replace=True) #Kondisi 1\n",
        "brtindtes2 = np.random.choice(indcites2, size=len(brtsampel2), p=ptes2, replace=True) #Kondisi 2\n",
        "#Penyatuan ke df (latihan)"
      ],
      "metadata": {
        "id": "h60f1faEFsRp"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap pembuatan berat sampel dengan indisitas (Latihan)\n",
        "brtsmplthmk2 = brtsmplth[brtindlth1]\n",
        "brtsmplthii = brtsmplth2[brtindlth2]\n",
        "#di data tes\n",
        "brtsampelmk2 = brtsampel[brtindtes1]\n",
        "brtsampelii = brtsampel2[brtindtes2]"
      ],
      "metadata": {
        "id": "ML_TAWnAGzAY"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tujuan pemasan berat di latihan adalah penstabilan data dengan indisitas\n",
        "- Indisitas dengan '1' dan '2' menyatakan kondisi rasio"
      ],
      "metadata": {
        "id": "RYUgBI2SCcSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rincian Percobaan\n",
        "* Percobaan pertama untuk kedua metode berlangsung dengan rasio (3/1) (1)\n",
        "* Percobaan kedua dengan rasio (31/9)"
      ],
      "metadata": {
        "id": "V3pdLLjkPFeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi penentu akurasi melalui KNN\n",
        "def train_and_evaluate(k):\n",
        "    model = KNeighborsClassifier(n_neighbors=k)\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Pembulatan metrik\n",
        "    accuracy = accuracy_score(y_test, y_pred, sample_weight=brtsampelmk2) # Akurasi yang dinormalkan\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampelmk2) # Penyesuaian di presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted',sample_weight=brtsampelmk2) #Penyesuaian di kondisi recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted',sample_weight=brtsampelmk2) #Penyesuaian di skor F1\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Total Tetangga k={k}\")\n",
        "    print(f\"Nilai Akurasi: {accuracy:.4f}, Presisi: {precision:.4f}, Aspek Recall: {recall:.4f}, Skor F1: {f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(y_test, y_pred, sample_weight=brtsampelmk2)\n",
        "\n",
        "    if (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "       (accuracy >= 0.92 and precision >= 0.92 and recall >= 0.92 and f1 >= 0.92):\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "         (accuracy < 0.92 and precision < 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "        print(\"Hasil masih bisa disimpan.\")\n",
        "        return (k, accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall < 0.87 and f1 < 0.87) or \\\n",
        "         (accuracy > 0.92 and precision > 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "         print(\"Ada masalah di recall dan nilai f1.\")\n",
        "         return None\n",
        "    else:\n",
        "        print(\"Hasil tidak pantas disimpan.\")\n",
        "        return None\n",
        "  #ke pembentukan matriks"
      ],
      "metadata": {
        "id": "4JYxBe87NLDk"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi evaluasi matriks\n",
        "def generate_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred, sample_weight=brtsampelmk2)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm_rounded = np.round(cm.astype(float), decimals=4)  # Pembulatan untuk kemudahan nilai\n",
        "    print(\"Hasil Confusion Matriks:\")\n",
        "    print(cm_rounded)\n",
        "    return cm_rounded\n",
        "#ke eksekusi asli"
      ],
      "metadata": {
        "id": "tMq4QAssNLip"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Deklarasi parameter batas di KNN\n",
        "param_grid = range(440,460)\n",
        "#Paralelisasi melalui KNN\n",
        "if __name__ == '__main__':\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(train_and_evaluate, param_grid)\n",
        "\n",
        "    # Filter out empty results\n",
        "    filtered_results = [result for result in results if result is not None]\n",
        "\n",
        "    # Get the best result\n",
        "    best_result = max(filtered_results, key=lambda x: x[1], default=None)\n",
        "\n",
        "    if best_result:\n",
        "        # Pembulatans\n",
        "        rounded_best_result = (\n",
        "            best_result[0],  # Nilai awal\n",
        "            round(best_result[1], 3),  # Pembulatan 1\n",
        "            round(best_result[2], 3),  # Pembulatan 2\n",
        "            round(best_result[3], 3),  # Pembulatan 3\n",
        "            round(best_result[4], 3),  # Pembulatan 4\n",
        "            best_result[5],  # Predictions (y_pred)\n",
        "            best_result[6]   # Informasi tambahan\n",
        "        )\n",
        "\n",
        "        # Simpan nilai terbaik dari dill\n",
        "        with open('best_knn_result.dill', 'wb') as f:\n",
        "            dill.dump(rounded_best_result, f)\n",
        "\n",
        "        _, _, _, _, _, y_pred, _ = rounded_best_result\n",
        "        cm = generate_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Simpan hasil matriks terbaik saja\n",
        "        with open('best_confusion_matrix.dill', 'wb') as cm_file:\n",
        "            dill.dump(cm, cm_file)\n",
        "\n",
        "        # Print the best rounded result\n",
        "        print(\"Best Result:\", rounded_best_result)\n",
        "#eksekusi KNN"
      ],
      "metadata": {
        "id": "VOTaGStgLZd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap pertama RFC (pelacakan nilai ccp alpha)\n",
        "nialpf = np.arange(1.2e-5, 0.012, 1.2e-4) #Nilai alfa\n",
        "itmaks = 350\n",
        "tolerance = 1.8e-3\n",
        "best_alpha = None\n",
        "best_accuracy = -np.inf\n",
        "best_f1 = -np.inf\n",
        "previous_best_accuracy = None\n",
        "#ke iterasi pelacakan nilai ccp alpha"
      ],
      "metadata": {
        "id": "povKRBbsg_hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi inspeksi nilai ccp alpha optimal\n",
        "def evaluasi_alfa(alpha):\n",
        "    rfc = RandomForestClassifier(random_state=50, ccp_alpha=alpha)\n",
        "    rfc.fit(X_train, y_train, sample_weight=brtsmplth)\n",
        "    y_pred = rfc.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Pembulatan akurasi\n",
        "    accuracy_rounded = round(accuracy, 3)\n",
        "    # Penghindaran Peringatan di normalisasi\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', sample_weight=brtsampelmk2, zero_division=0)  # Nilai f1\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampelmk2, zero_division=0)  # indikator presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', sample_weight=brtsampelmk2, zero_division=0)  # Nilai Recall\n",
        "\n",
        "    return alpha, accuracy_rounded, f1, precision, recall  # Return values\n",
        "\n",
        "# Iterasi melalui jangkauan nilai alfa\n",
        "for iteration in range(itmaks):\n",
        "    with Pool() as pool:\n",
        "        results = pool.map(evaluasi_alfa, nialpf)\n",
        "\n",
        "    for alpha, accuracy, f1, precision, recall in results:\n",
        "        if accuracy > best_accuracy or (accuracy == best_accuracy and f1 > best_f1):\n",
        "            best_alpha = alpha\n",
        "            best_accuracy = accuracy\n",
        "            best_f1 = f1\n",
        "\n",
        "        # Pemeriksaan untuk nilai minimal (atau optimal)\n",
        "        if (accuracy >= 0.92 and precision >= 0.92 and\n",
        "            recall >= 0.92 and f1 >= 0.92) or \\\n",
        "           (accuracy >= 0.87 and precision >= 0.87 and\n",
        "            recall >= 0.87 and f1 >= 0.87):\n",
        "            print(f\"Optimal metrics reached with ccp_alpha: {alpha}, \"\n",
        "                  f\"Akurasi: {accuracy:.3f}, F1 Score: {f1:.2f}, \"\n",
        "                  f\"Precision: {precision:.2f}, Recall: {recall:.2f}. Stopping search.\")\n",
        "            break\n",
        "\n",
        "    # Pengaturan Nilai alfa\n",
        "    nialpf = np.linspace(max(0.001, best_alpha - 0.005), min(0.1, best_alpha + 0.005), num=10)\n",
        "\n",
        "    # Check for tolerance to stop early\n",
        "    if iteration > 0 and abs(best_accuracy - previous_best_accuracy) < tolerance:\n",
        "        print(\"Penghentian terjadi karena sudah melewati batas toleransi.\")\n",
        "        break\n",
        "\n",
        "    previous_best_accuracy = best_accuracy\n",
        "\n",
        "# Final results output\n",
        "print(f'Nilai ccp_alpha terbaik: {best_alpha}, Accuracy: {best_accuracy:.3f}, F1 Score: {best_f1:.2f}')\n",
        "#ke fungsi RFC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Le6fLizfigZG",
        "outputId": "a343a5dc-90e0-43b3-e2d5-30f9beb1a4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Penghentian terjadi karena sudah melewati batas toleransi.\n",
            "Nilai ccp_alpha terbaik: 1.2e-05, Accuracy: 0.468, F1 Score: 0.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fungsi dengan teknik RFC\n",
        "final_model = RandomForestClassifier(random_state=50, ccp_alpha=best_alpha)\n",
        "final_model.fit(X_train, y_train)\n",
        "y_pred_final = final_model.predict(X_test)\n",
        "#Ke evaluasi"
      ],
      "metadata": {
        "id": "PrItSs5glrvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluasi melalui laporan dan 'confusion matrix'\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
        "class_report = classification_report(y_test, y_pred_final)\n",
        "#pencetakan nilai matriks\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nLaporan Klasifikasi:\")\n",
        "print(class_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNvQCgi4l3Md",
        "outputId": "a6f57c15-16b5-4763-b439-224e371ec6db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[3811 1301  763]\n",
            " [2103 2396  787]\n",
            " [2008 1509 1326]]\n",
            "\n",
            "Laporan Klasifikasi:\n",
            "                                                        precision    recall  f1-score   support\n",
            "\n",
            "                 game dengan tujuan utama pencari duit       0.48      0.65      0.55      5875\n",
            "                game favortit dengan keuntungan rendah       0.46      0.45      0.46      5286\n",
            "game kurang berkenan dengan fokus pencarian keuntungan       0.46      0.27      0.34      4843\n",
            "\n",
            "                                              accuracy                           0.47     16004\n",
            "                                             macro avg       0.47      0.46      0.45     16004\n",
            "                                          weighted avg       0.47      0.47      0.46     16004\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis narasi atau penjelasan algoritma yang Anda gunakan.\n",
        "### Rincian pemakaian algoritma KNN (K-nearest Neighboorhood)\n",
        "1. Persiapan numerisasi label **'onehotencoding'**\n",
        "2. Proses standardisasi kolom numerik dengan **\"Robustscaler\"**\n",
        "3. Eksekusi dengan teknik KNN melalui beberapa tahap :\n",
        "#### 3.a. Proses Pelatihan dan evaluasi nilai gama dalam jangkauan dinamis\n",
        "#### 3.b. Proses Paralelisasi untuk eksekusi dan evaluasi\n",
        "#### 3.c. Tahap pencetakan Nilai akurasi, presisi 'recall'\n",
        "### Rincian pemkaian algoritma RFC (Random Forest Classifier)\n",
        "* Persiapan numerisasi label dengan **'onehotencoding'**\n",
        "* proses standardisasi dengan metode sama (agar lebih adil)\n",
        "* Eksekusi fungsi yang terdiri dari\n",
        "** a. Pelatihan RFC dengan RandomSearch CV untuk modifikasi nanti\n",
        "** b. Tahapan paralelisasi untuk RFC\n",
        "** c. Tahap pencetakan nilai RFC"
      ],
      "metadata": {
        "id": "seYoHNY3XU1y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **b. Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ergzChZFEL-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Lakukan prediksi menggunakan data uji.\n",
        "2. Hitung metrik evaluasi seperti Accuracy dan F1-Score (Opsional: Precision dan Recall).\n",
        "3. Buat confusion matrix untuk melihat detail prediksi benar dan salah."
      ],
      "metadata": {
        "id": "zOm68u-7NpLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tulis hasil evaluasi algoritma yang digunakan, jika Anda menggunakan 2 algoritma, maka bandingkan hasilnya.\n",
        "\n",
        "## Evaluasi algoritma antara Hasil 'tetangga terdekat' dengan teknik 'randomforest'\n",
        "### Evaluasi dengan teknik KNN\n",
        "#### 1. Hasil mengalmi fluktuasi rendah nilai akurasi presisi indeks 'recall' dan skor f1\n",
        "#### 2. Nilai masih belum mencapai akurasi minimal walau nilai dipasang pemberat\n",
        "#### 3.  \n",
        "### Evaluasi dnegan teknik RFC\n",
        "#### a. Nilai masih terlalu rendah baik tanpa pemberatan ataupun pemberatan\n",
        "#### b."
      ],
      "metadata": {
        "id": "H4_9OwrsXZlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **c. Tuning Model Klasifikasi (Optional)**"
      ],
      "metadata": {
        "id": "ph9yIYDXEPuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan GridSearchCV, RandomizedSearchCV, atau metode lainnya untuk mencari kombinasi hyperparameter terbaik"
      ],
      "metadata": {
        "id": "-Bikx3LINv5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi di teknik KNN"
      ],
      "metadata": {
        "id": "26aTlch94foS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inisiasi grid search di KNN\n",
        "def tuned_train_and_evaluate(X_train, y_train, X_test, y_test, brtsampel):\n",
        "  # Define the KNN model\n",
        "    knn = KNeighborsClassifier()\n",
        "\n",
        "    # Define the parameter grid for Randomized Search\n",
        "    param_dist = {\n",
        "        'n_neighbors': range(440, 460),  # Penyetelan\n",
        "        'weights': ['uniform', 'distance'],\n",
        "        'metric': ['euclidean', 'manhattan']\n",
        "    }\n",
        "\n",
        "    # Initialize RandomizedSearchCV\n",
        "    random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=20, cv=5, random_state=42)\n",
        "\n",
        "    # Fit the model\n",
        "    random_search.fit(X_train, y_train)\n",
        "\n",
        "    # Prediksi model terbaik\n",
        "    y_pred = random_search.predict(X_test)\n",
        "\n",
        "    # Pembulatan metrik\n",
        "    accuracy = accuracy_score(y_test, y_pred, sample_weight=brtsampel)  # Akurasi yang dinormalkan\n",
        "    precision = precision_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di presisi\n",
        "    recall = recall_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di kondisi recall\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted', sample_weight=brtsampel)  # Penyesuaian di skor F1\n",
        "\n",
        "    # Cetak Metrik\n",
        "    print(f\"Best Parameters: {random_search.best_params_}\")\n",
        "    print(f\"Nilai Akurasi: {accuracy:.4f}, Presisi: {precision:.4f}, Aspek Recall: {recall:.4f}, Skor F1: {f1:.4f}\")\n",
        "\n",
        "    # Classification report\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    if (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "       (accuracy >= 0.92 and precision >= 0.92 and recall >= 0.92 and f1 >= 0.92):\n",
        "        return (random_search.best_params_['n_neighbors'], accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall >= 0.87 and f1 >= 0.87) or \\\n",
        "         (accuracy < 0.92 and precision < 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "        print(\"Hasil masih bisa disimpan.\")\n",
        "        return (random_search.best_params_['n_neighbors'], accuracy, precision, recall, f1, y_pred, report)\n",
        "    elif (accuracy >= 0.87 and precision >= 0.87 and recall < 0.87 and f1 < 0.87) or \\\n",
        "         (accuracy > 0.92 and precision > 0.92 and recall < 0.92 and f1 < 0.92):\n",
        "         print(\"Ada masalah di recall dan nilai f1.\")\n",
        "         return None\n",
        "    else:\n",
        "        print(\"Hasil tidak pantas disimpan.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "OK0T2WS34lK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan tuning di KNN (matriks)\n",
        "def tuned_confusion_matrix(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    cm_rounded = np.round(cm.astype(float), decimals=4)  # Pembulatan untuk kemudahan nilai\n",
        "    print(\"Hasil Confusion Matriks:\")\n",
        "    print(cm_rounded)\n",
        "    return cm_rounded\n",
        "#ke eksekusi akhir"
      ],
      "metadata": {
        "id": "winbFzb8NL95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Eksekusi dengan Randomized search\n",
        "if __name__ == '__main__':\n",
        "    # Definisi pemberatan\n",
        "    result = tuned_train_and_evaluate(X_train, y_train, X_test, y_test, brtsampel)\n",
        "\n",
        "    if result:\n",
        "        k_value = result[0]\n",
        "        rounded_results = tuple(round(x, 3) if isinstance(x, float) else x for x in result)\n",
        "\n",
        "        # Simpan nilai terbaik dari dill\n",
        "        with open('tuned_knn_result.dill', 'wb') as f:\n",
        "            dill.dump(rounded_results, f)\n",
        "\n",
        "        _, _, _, _, _, y_pred, _ = rounded_results\n",
        "        cm = generate_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "        # Simpan hasil matriks terbaik saja\n",
        "        with open('tuned_confusion_matrix.dill', 'wb') as cm_file:\n",
        "            dill.dump(cm, cm_file)\n",
        "\n",
        "        # Print the best rounded result\n",
        "        print(\"Best Result:\", rounded_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMyTCQctRbN-",
        "outputId": "5336aeed-6ced-4d3d-dcea-008d083bfff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'weights': 'distance', 'n_neighbors': 198, 'metric': 'manhattan'}\n",
            "Nilai Akurasi: 0.4387, Presisi: 0.4443, Aspek Recall: 0.4387, Skor F1: 0.4244\n",
            "Hasil masih bisa disimpan.\n",
            "Confusion Matrix:\n",
            "Hasil Confusion Matriks:\n",
            "[[3383.3137 1222.2062  729.1468]\n",
            " [2211.1719 2291.9084  831.5863]\n",
            " [2325.311  1663.2969 1346.0588]]\n",
            "Best Result: (198, 0.439, 0.444, 0.439, 0.424, array(['game favortit dengan keuntungan rendah',\n",
            "       'game kurang berkenan dengan fokus pencarian keuntungan',\n",
            "       'game favortit dengan keuntungan rendah', ...,\n",
            "       'game dengan tujuan utama pencari duit',\n",
            "       'game favortit dengan keuntungan rendah',\n",
            "       'game dengan tujuan utama pencari duit'], dtype=object), '                                                        precision    recall  f1-score   support\\n\\n                 game dengan tujuan utama pencari duit       0.46      0.63      0.54      5875\\n                game favortit dengan keuntungan rendah       0.44      0.43      0.44      5286\\ngame kurang berkenan dengan fokus pencarian keuntungan       0.43      0.25      0.32      4843\\n\\n                                              accuracy                           0.45     16004\\n                                             macro avg       0.45      0.44      0.43     16004\\n                                          weighted avg       0.45      0.45      0.44     16004\\n')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modifikasi RCT"
      ],
      "metadata": {
        "id": "5QFhKKQp4nWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tahap awal di RCT\n"
      ],
      "metadata": {
        "id": "Yr-zYpk156TH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Lanjutan di RCT"
      ],
      "metadata": {
        "id": "WQRB-bOs6Jsu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **d. Evaluasi Model Klasifikasi setelah Tuning (Optional)**"
      ],
      "metadata": {
        "id": "hE7pqlEPEYzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah rekomendasi tahapannya.\n",
        "1. Gunakan model dengan hyperparameter terbaik.\n",
        "2. Hitung ulang metrik evaluasi untuk melihat apakah ada peningkatan performa."
      ],
      "metadata": {
        "id": "feaPESoeN0zz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode Support Vector Machine\n"
      ],
      "metadata": {
        "id": "ZApbldsp59T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Inspeksi di metode RandomForestClasifier\n"
      ],
      "metadata": {
        "id": "HTXZRvEeNMb1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **e. Analisis Hasil Evaluasi Model Klasifikasi**"
      ],
      "metadata": {
        "id": "ZRsOdm4uEgAW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut adalah **rekomendasi** tahapannya.\n",
        "1. Bandingkan hasil evaluasi sebelum dan setelah tuning (jika dilakukan).\n",
        "2. Identifikasi kelemahan model, seperti:\n",
        "  - Precision atau Recall rendah untuk kelas tertentu.\n",
        "  - Apakah model mengalami overfitting atau underfitting?\n",
        "3. Berikan rekomendasi tindakan lanjutan, seperti mengumpulkan data tambahan atau mencoba algoritma lain jika hasil belum memuaskan."
      ],
      "metadata": {
        "id": "Hm3BhSi6N4_l"
      }
    }
  ]
}